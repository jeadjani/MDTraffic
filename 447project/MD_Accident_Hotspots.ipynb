{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import folium\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from API\n",
    "def load_data_from_api(url):\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Loading data from APIs (if used)\n",
    "# Example API for traffic stops\n",
    "traffic_stops_url = 'https://opendata.maryland.gov/resource/tx73-47dk.json'\n",
    "traffic_stops_data = load_data_from_api(traffic_stops_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory\n",
    "base_dir = Path('projectdata')\n",
    "\n",
    "# Specific files\n",
    "aadt_points_file = base_dir / 'Maryland_Annual_Average_Daily_Traffic_-_Annual_Average_Daily_Traffic_(SHA_Statewide_AADT_Points).csv'\n",
    "aadt_lines_file = base_dir / 'Maryland_Annual_Average_Daily_Traffic_-_Annual_Average_Daily_Traffic_(SHA_Statewide_AADT_Lines).csv'\n",
    "pedestrian_injury_file = base_dir / 'SHIP_Pedestrian_Injury_Rate_on_Public_Roads_2009-2022_20240505.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aquil\\AppData\\Local\\Temp/ipykernel_20248/2405018586.py:4: DtypeWarning: Columns (100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  aadt_points_data = pd.read_csv(aadt_points_file)\n",
      "C:\\Users\\aquil\\AppData\\Local\\Temp/ipykernel_20248/2405018586.py:9: DtypeWarning: Columns (98) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  aadt_lines_data = pd.read_csv(aadt_lines_file)\n"
     ]
    }
   ],
   "source": [
    "if not aadt_points_file.exists():\n",
    "    print(f\"The file {aadt_points_file} does not exist!\")\n",
    "else:\n",
    "    aadt_points_data = pd.read_csv(aadt_points_file)\n",
    "\n",
    "if not aadt_lines_file.exists():\n",
    "    print(f\"The file {aadt_lines_file} does not exist!\")\n",
    "else:\n",
    "    aadt_lines_data = pd.read_csv(aadt_lines_file)\n",
    "\n",
    "if not pedestrian_injury_file.exists():\n",
    "    print(f\"The file {pedestrian_injury_file} does not exist!\")\n",
    "else:\n",
    "    pedestrian_injury_data = pd.read_csv(pedestrian_injury_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aquil\\AppData\\Local\\Temp/ipykernel_20248/3372450109.py:1: DtypeWarning: Columns (100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  aadt_points_data = pd.read_csv(aadt_points_file)\n",
      "C:\\Users\\aquil\\AppData\\Local\\Temp/ipykernel_20248/3372450109.py:2: DtypeWarning: Columns (98) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  aadt_lines_data = pd.read_csv(aadt_lines_file)\n"
     ]
    }
   ],
   "source": [
    "aadt_points_data = pd.read_csv(aadt_points_file)\n",
    "aadt_lines_data = pd.read_csv(aadt_lines_file)\n",
    "pedestrian_injury_data = pd.read_csv(pedestrian_injury_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General cleaning for all datasets\n",
    "def clean_data(df):\n",
    "    # Example: Convert dates, handle missing values\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "aadt_points_data = clean_data(aadt_points_data)\n",
    "aadt_lines_data = clean_data(aadt_lines_data)\n",
    "pedestrian_injury_data = clean_data(pedestrian_injury_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Location'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20248/3601661169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Merging data examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Assuming common columns 'Date' and 'Location' for simplicity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcombined_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maadt_points_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maadt_lines_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Location'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcombined_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpedestrian_injury_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Location'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aquil\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 107\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aquil\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aquil\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aquil\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1846\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Location'"
     ]
    }
   ],
   "source": [
    "# Merging data examples\n",
    "# Assuming common columns 'Date' and 'Location' for simplicity\n",
    "combined_data = pd.merge(aadt_points_data, aadt_lines_data, on=['Location'], how='inner')\n",
    "combined_data = pd.merge(combined_data, pedestrian_injury_data, on=['Date', 'Location'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in aadt_points_data: Index(['X', 'Y', 'OBJECTID', 'LOCATION_ID', 'COUNTY_ID', 'COUNTY_DESC',\n",
      "       'MUN_SORT', 'MUNICIPALITY', 'ROADNAME', 'ID_PREFIX',\n",
      "       ...\n",
      "       'AAWDT_2017_ANNO', 'AAWDT_2018_ANNO', 'AAWDT_ANNO',\n",
      "       'MOTORCYCLE_AADT_ANNO', 'CAR_AADT_ANNO', 'BUS_AADT_ANNO',\n",
      "       'LIGHT_TRUCK_AADT_ANNO', 'SINGLE_UNIT_AADT_ANNO',\n",
      "       'COMBINATION_UNIT_AADT_ANNO', 'TRUCK_AADT_ANNO'],\n",
      "      dtype='object', length=102)\n",
      "Columns in aadt_lines_data: Index(['OBJECTID', 'LOCATION_ID', 'COUNTY_ID', 'COUNTY_DESC', 'MUN_SORT',\n",
      "       'MUNICIPALITY', 'ROADNAME', 'ID_PREFIX', 'ID_RTE_NO', 'MP_SUFFIX',\n",
      "       ...\n",
      "       'AAWDT_2018_ANNO', 'AAWDT_ANNO', 'MOTORCYCLE_AADT_ANNO',\n",
      "       'CAR_AADT_ANNO', 'BUS_AADT_ANNO', 'LIGHT_TRUCK_AADT_ANNO',\n",
      "       'SINGLE_UNIT_AADT_ANNO', 'COMBINATION_UNIT_AADT_ANNO',\n",
      "       'TRUCK_AADT_ANNO', 'Shape_Length'],\n",
      "      dtype='object', length=102)\n",
      "Columns in pedestrian_injury_data: Index(['Jurisdiction', 'Value', 'Race/ ethnicity', 'Year', 'Measure'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in aadt_points_data:\", aadt_points_data.columns)\n",
    "print(\"Columns in aadt_lines_data:\", aadt_lines_data.columns)\n",
    "print(\"Columns in pedestrian_injury_data:\", pedestrian_injury_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary and correlations\n",
    "print(combined_data.describe())\n",
    "sns.heatmap(combined_data.corr(), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex analyses like regression, clustering, etc.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example: Linear regression to predict AADT from other factors\n",
    "model = LinearRegression()\n",
    "model.fit(combined_data[['Num_Lanes']], combined_data['AADT'])\n",
    "predictions = model.predict(combined_data[['Num_Lanes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic visualization of traffic data\n",
    "map = folium.Map(location=[38.9072, -76.8569], zoom_start=10)\n",
    "for idx, row in combined_data.iterrows():\n",
    "    folium.CircleMarker([row['Latitude'], row['Longitude']], radius=5, popup=str(row['AADT']), color='red').add_to(map)\n",
    "map.save('Traffic_Map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key findings and provide recommendations based on the analysis\n",
    "print(\"Traffic volumes are highest on roads with X characteristic, suggesting Y policy interventions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
